{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.segmentation import clear_border\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import imutils\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cases yet to Consider:\n",
    "* European and international plates are often longer and not as tall as United States license plates.\n",
    "* Some countries and regions allow for multi-line plates with a near 1:1 aspect ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PyImageSearchANPR:\n",
    "\tdef __init__(self, minAR=4, maxAR=5, debug=False):\n",
    "\t\t# store the minimum and maximum rectangular aspect ratio\n",
    "\t\t# values along with whether or not we are in debug mode\n",
    "\t\tself.minAR = minAR\n",
    "\t\tself.maxAR = maxAR\n",
    "\t\tself.debug = debug\n",
    "\n",
    "\tdef debug_imshow(self, title, image, waitKey=False):\n",
    "\t\t# check to see if we are in debug mode, and if so, show the\n",
    "\t\t# image with the supplied title\n",
    "\t\tif self.debug:\n",
    "\t\t\tcv2.imshow(title, image)\n",
    "\t\t\t# check to see if we should wait for a keypress\n",
    "\t\t\tif waitKey:\n",
    "\t\t\t\tcv2.waitKey(0)\n",
    "    \n",
    "\tdef locate_license_plate_candidates(self, gray, keep=5):\n",
    "\t\t# perform a blackhat morphological operation that will allow\n",
    "\t\t# us to reveal dark regions (i.e., text) on light backgrounds\n",
    "\t\t# (i.e., the license plate itself)\n",
    "\t\trectKern = cv2.getStructuringElement(cv2.MORPH_RECT, (13, 5))\n",
    "\t\tblackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, rectKern)\n",
    "\t\tself.debug_imshow(\"Blackhat\", blackhat)\n",
    "        # next, find regions in the image that are light\n",
    "\t\tsquareKern = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))\n",
    "\t\tlight = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, squareKern)\n",
    "\t\tlight = cv2.threshold(light, 0, 255,\n",
    "\t\t\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\t\tself.debug_imshow(\"Light Regions\", light)\n",
    "\n",
    "        # compute the Scharr gradient representation of the blackhat\n",
    "\t\t# image in the x-direction and then scale the result back to\n",
    "\t\t# the range [0, 255]\n",
    "\t\tgradX = cv2.Sobel(blackhat, ddepth=cv2.CV_32F,\n",
    "\t\t\tdx=1, dy=0, ksize=-1)\n",
    "\t\tgradX = np.absolute(gradX)\n",
    "\t\t(minVal, maxVal) = (np.min(gradX), np.max(gradX))\n",
    "\t\tgradX = 255 * ((gradX - minVal) / (maxVal - minVal))\n",
    "\t\tgradX = gradX.astype(\"uint8\")\n",
    "\t\tself.debug_imshow(\"Scharr\", gradX)\n",
    "\n",
    "        # blur the gradient representation, applying a closing\n",
    "\t\t# operation, and threshold the image using Otsu's method\n",
    "\t\tgradX = cv2.GaussianBlur(gradX, (5, 5), 0)\n",
    "\t\tgradX = cv2.morphologyEx(gradX, cv2.MORPH_CLOSE, rectKern)\n",
    "\t\tthresh = cv2.threshold(gradX, 0, 255,\n",
    "\t\t\tcv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "\t\tself.debug_imshow(\"Grad Thresh\", thresh)\n",
    "\n",
    "        # perform a series of erosions and dilations to clean up the\n",
    "\t\t# thresholded image\n",
    "\t\tthresh = cv2.erode(thresh, None, iterations=2)\n",
    "\t\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\t\tself.debug_imshow(\"Grad Erode/Dilate\", thresh)\n",
    "\n",
    "        # take the bitwise AND between the threshold result and the\n",
    "\t\t# light regions of the image\n",
    "\t\tthresh = cv2.bitwise_and(thresh, thresh, mask=light)\n",
    "\t\tthresh = cv2.dilate(thresh, None, iterations=2)\n",
    "\t\tthresh = cv2.erode(thresh, None, iterations=1)\n",
    "\t\tself.debug_imshow(\"Final\", thresh, waitKey=True)\n",
    "\n",
    "        # find contours in the thresholded image and sort them by\n",
    "\t\t# their size in descending order, keeping only the largest\n",
    "\t\t# ones\n",
    "\t\tcnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\t\t\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "\t\tcnts = imutils.grab_contours(cnts)\n",
    "\t\tcnts = sorted(cnts, key=cv2.contourArea, reverse=True)[:keep]\n",
    "\t\t# return the list of contours\n",
    "\t\treturn cnts\n",
    "\n",
    "\tdef locate_license_plate(self, gray, candidates,\n",
    "\t\tclearBorder=False):\n",
    "\t\t# initialize the license plate contour and ROI\n",
    "\t\tlpCnt = None\n",
    "\t\troi = None\n",
    "\t\t# loop over the license plate candidate contours\n",
    "\t\tfor c in candidates:\n",
    "\t\t\t# compute the bounding box of the contour and then use\n",
    "\t\t\t# the bounding box to derive the aspect ratio\n",
    "\t\t\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t\t\tar = w / float(h)\n",
    "    \n",
    "            # check to see if the aspect ratio is rectangular\n",
    "\t\t\tif ar >= self.minAR and ar <= self.maxAR:\n",
    "\t\t\t\t# store the license plate contour and extract the\n",
    "\t\t\t\t# license plate from the grayscale image and then\n",
    "\t\t\t\t# threshold it\n",
    "\t\t\t\tlpCnt = c\n",
    "\t\t\t\tlicensePlate = gray[y:y + h, x:x + w]\n",
    "\t\t\t\troi = cv2.threshold(licensePlate, 0, 255, cv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "                # check to see if we should clear any foreground\n",
    "\t\t\t\t# pixels touching the border of the image\n",
    "\t\t\t\t# (which typically, not but always, indicates noise)\n",
    "\t\t\t\tif clearBorder:\n",
    "\t\t\t\t\troi = clear_border(roi)\n",
    "\t\t\t\t# display any debugging information and then break\n",
    "\t\t\t\t# from the loop early since we have found the license\n",
    "\t\t\t\t# plate region\n",
    "\t\t\t\tself.debug_imshow(\"License Plate\", licensePlate)\n",
    "\t\t\t\tself.debug_imshow(\"ROI\", roi, waitKey=True)\n",
    "\t\t\t\tbreak\n",
    "\t\t# return a 2-tuple of the license plate ROI and the contour\n",
    "\t\t# associated with it\n",
    "\t\treturn (roi, lpCnt)\n",
    "        \n",
    "\tdef build_tesseract_options(self, psm=7):\n",
    "\t\t# tell Tesseract to only OCR alphanumeric characters\n",
    "\t\talphanumeric = \"ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "\t\toptions = \"-c tessedit_char_whitelist={}\".format(alphanumeric)\n",
    "\t\t# set the PSM mode\n",
    "\t\toptions += \" --psm {}\".format(psm)\n",
    "\t\t# return the built options string\n",
    "\t\treturn options\n",
    "\n",
    "\tdef find_and_ocr(self, image, psm=7, clearBorder=False):\n",
    "\t\t# initialize the license plate text\n",
    "\t\tlpText = None\n",
    "\t\t# convert the input image to grayscale, locate all candidate\n",
    "\t\t# license plate regions in the image, and then process the\n",
    "\t\t# candidates, leaving us with the *actual* license plate\n",
    "\t\tgray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\t\tcandidates = self.locate_license_plate_candidates(gray)\n",
    "\t\t(lp, lpCnt) = self.locate_license_plate(gray, candidates,\n",
    "\t\t\tclearBorder=clearBorder)\n",
    "\t\t# only OCR the license plate if the license plate ROI is not\n",
    "\t\t# empty\n",
    "\t\tif lp is not None:\n",
    "\t\t\t# OCR the license plate\n",
    "\t\t\toptions = self.build_tesseract_options(psm=psm)\n",
    "\t\t\tlpText = pytesseract.image_to_string(lp, config=options)\n",
    "\t\t\tself.debug_imshow(\"License Plate\", lp)\n",
    "\t\t# return a 2-tuple of the OCR'd license plate text along with\n",
    "\t\t# the contour associated with the license plate region\n",
    "\t\treturn (lpText, lpCnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyimagesearch.anpr import PyImageSearchANPR\n",
    "from imutils import paths\n",
    "import argparse\n",
    "import imutils\n",
    "import cv2\n",
    "\n",
    "def cleanup_text(text):\n",
    "\t# strip out non-ASCII text so we can draw the text on the image\n",
    "\t# using OpenCV\n",
    "\treturn \"\".join([c if ord(c) < 128 else \"\" for c in text]).strip()\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-i\", \"--input\", required=True,\n",
    "\thelp=\"path to input directory of images\")\n",
    "ap.add_argument(\"-c\", \"--clear-border\", type=int, default=-1,\n",
    "\thelp=\"whether or to clear border pixels before OCR'ing\")\n",
    "ap.add_argument(\"-p\", \"--psm\", type=int, default=7,\n",
    "\thelp=\"default PSM mode for OCR'ing license plates\")\n",
    "ap.add_argument(\"-d\", \"--debug\", type=int, default=-1,\n",
    "\thelp=\"whether or not to show additional visualizations\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "# initialize our ANPR class\n",
    "anpr = PyImageSearchANPR(debug=args[\"debug\"] > 0)\n",
    "# grab all image paths in the input directory\n",
    "imagePaths = sorted(list(paths.list_images(args[\"input\"])))\n",
    "\n",
    "# loop over all image paths in the input directory\n",
    "for imagePath in imagePaths:\n",
    "\t# load the input image from disk and resize it\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = imutils.resize(image, width=600)\n",
    "\t# apply automatic license plate recognition\n",
    "\t(lpText, lpCnt) = anpr.find_and_ocr(image, psm=args[\"psm\"],\n",
    "\t\tclearBorder=args[\"clear_border\"] > 0)\n",
    "\t# only continue if the license plate was successfully OCR'd\n",
    "\tif lpText is not None and lpCnt is not None:\n",
    "\t\t# fit a rotated bounding box to the license plate contour and\n",
    "\t\t# draw the bounding box on the license plate\n",
    "\t\tbox = cv2.boxPoints(cv2.minAreaRect(lpCnt))\n",
    "\t\tbox = box.astype(\"int\")\n",
    "\t\tcv2.drawContours(image, [box], -1, (0, 255, 0), 2)\n",
    "\t\t# compute a normal (unrotated) bounding box for the license\n",
    "\t\t# plate and then draw the OCR'd license plate text on the\n",
    "\t\t# image\n",
    "\t\t(x, y, w, h) = cv2.boundingRect(lpCnt)\n",
    "\t\tcv2.putText(image, cleanup_text(lpText), (x, y - 15),\n",
    "\t\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.75, (0, 255, 0), 2)\n",
    "\t\t# show the output ANPR image\n",
    "\t\tprint(\"[INFO] {}\".format(lpText))\n",
    "\t\tcv2.imshow(\"Output ANPR\", image)\n",
    "\t\tcv2.waitKey(0)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
